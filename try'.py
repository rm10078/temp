# -*- coding: utf-8 -*-
"""try'.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_Q4ewywneqYLuXJICAYmPOC82HGdQznd
"""

import pandas as pd

data=pd.read_csv('/content/Book2.csv')

data['MONTH'] = data[['Year', 'Mon']].apply(lambda x: '{}-{}'.format(x[1], x[0]), axis=1)

data=data.drop("Year",axis='columns')
data=data.drop("Mon",axis='columns')

data['MONTH']=pd.to_datetime(data['MONTH'])

data=data.set_index('MONTH')

data

import numpy as np

from sklearn.preprocessing import MinMaxScaler
normalizer = MinMaxScaler(feature_range=(0,1))
data_scaled = normalizer.fit_transform(np.array(data).reshape(-1,1))

import numpy as np
def prepare_data(timeseries_data, n_steps):
	X, y =[],[]
	for i in range(len(timeseries_data)):
		# find the end of this pattern
		end_ix = i + n_steps
		# check if we are beyond the sequence
		if end_ix > len(timeseries_data)-1:
			break
		# gather input and output parts of the pattern
		seq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]
		X.append(seq_x)
		y.append(seq_y)
	return np.array(X), np.array(y)

from keras.models import Sequential
from keras.layers import Dense,Dropout
from keras.layers import LSTM,Conv1D,Bidirectional


from sklearn import metrics
import tensorflow as tf

def create_model():
  model=Sequential()
  model.add(LSTM(87,activation='relu',input_shape=(n_steps,1),return_sequences=True))
  model.add(Dropout(.3))
  model.add(LSTM(97,activation='selu'))
  model.add(Dense(1))
  model.compile(optimizer='adam',loss='mse',metrics=[tf.keras.metrics.RootMeanSquaredError()])
  return model

from tensorflow.keras.callbacks import EarlyStopping
early_stopping = EarlyStopping(patience=20, monitor='val_loss')
early_stopping1 = EarlyStopping(patience=10,monitor= 'val_root_mean_squared_error' )

train_size=[.6]
a=[]
t=[]
b=[]

from sklearn.metrics import mean_squared_error
import random
from math import sqrt
best_rmse=200
for s in train_size:
  n = len(data)
  c=3
  r1=15
  r2=15+c
  train_df = data_scaled[0:int(n*s)]
  test_df = data_scaled[int(n*s):]
  while r1 < len(test_df):
    w = random.randrange(r1,r2)
    n_steps=w
    X,y=prepare_data(train_df,n_steps)
    val_X,val_y=prepare_data(test_df,n_steps)
    X = X.reshape(X.shape[0],X.shape[1] , 1)
    val_X = val_X.reshape(val_X.shape[0],val_X.shape[1] , 1)
    model= create_model()
    model.fit(X,y,batch_size=32,epochs=100,verbose=0,callbacks=[early_stopping,early_stopping1],validation_data=(val_X,val_y))
    train_predict = model.predict(X)
    test_data=normalizer.inverse_transform(val_y)
    test_predict = model.predict(val_X)
    train_predict = normalizer.inverse_transform(train_predict)
    test_predict = normalizer.inverse_transform(test_predict)
    rmse = np.sqrt(mean_squared_error(test_data, test_predict))
    a.append(rmse)
    t.append(s)
    b.append(w)
    if r2+c < len(test_df):
      r1=r1+c
      r2=r2+c
    else:
      r1=r1+c
      r2=len(test_df)
    print(f"LSTM RMSE FOR WINDOW SIZE {w} & test size {s}:", rmse)
    if rmse<best_rmse:
      model.save_weights(f'model_lstm_l1{s}&{w}.h5')
      best_rmse=rmse
      window=w

best_rmse,window

DF2 = pd.DataFrame()
DF2['TRAIN SIZE']=t
DF2['WINDOW SIZE']=b
DF2['RMSE']=a

DF2.to_csv('train_lstm_l2_size_.6.csv')